#Default params for running indexing using Pignlproc scripts
# input: Wikipedia XML dump
INPUT=/home/chris/projects/pignlproc/src/test/resources/enwiki-latest-pages-articles-1000.xml
#INPUT=/media/Chris\ 2TB/wikidumps/enwiki-20120601-pages-articles.xml
#INPUT=src/test/resources/enwiki-pages-articles-sample.xml
#INPUT=src/test/resources/frwiki-20101103-pages-articles-sample.xml
#INPUT = /home/chris/projects/Twopics/perl/out.txt
#INPUT = /home/chris/data/twopics/categories/script_6/topics_abstracts.tsv

#Testing with index inputs
INVERTED_INDEX=/home/chris/data/pig_output/indexes/inverted/en.tfidf_inverted_index-1000.tsv
TFIDF_INDEX=/home/chris/data/pig_output/indexes/tfidf/en.tfidf_token_weights-1000.tsv


#Configuration
MAX_SPAN_LENGTH=5000
MIN_COUNT=1
MIN_CONTEXTS=1
MIN_SURFACE_FORM_LENGTH=1
#NUM_DOCS=1000
NUM_DOCS=7519283
N=100

#Lucene Analyzer to use (language-specific)
LANG=en
ANALYZER_NAME=EnglishAnalyzer
#LANG=fr
#ANALYZER_NAME=FrenchAnalyzer


# output directory on local filesystem 
OUTPUT_DIR=/tmp/output
# output dir on pseudo-distributed HDFS
#OUTPUT_DIR=/user/chris/output

#Location of the list of URIs to keep
URI_LIST=/home/chris/projects/pignlproc/src/test/resources/uri_list.txt

# location of the stop word list file in HDFS
STOPLIST_NAME=stopwords.en.list
STOPLIST_PATH=/home/chris/projects/pignlproc
# local path to JAR containing UDFs
PIGNLPROC_JAR=/home/chris/projects/pignlproc/target/pignlproc-0.1.0-SNAPSHOT.jar
# number of reducers
DEFAULT_PARALLEL=15
